{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Copia de autoencoders-for-anomaly-detection-training.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsoy/data/blob/main/Copia_de_autoencoders_for_anomaly_detection_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR5LkbrLRDhf"
      },
      "source": [
        "# **Introduction to convolutional neural network (CNN)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK0zxrrKRDhi"
      },
      "source": [
        "Convolutional neural network is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI3gZMK7RDhj"
      },
      "source": [
        "![](https://miro.medium.com/max/3288/1*uAeANQIOQPqWZnnuH-VEyw.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "-W4djq60RDhj"
      },
      "source": [
        "**Convolution operation on a MxNx3 image matrix with a 3x3x3 Kernel**\n",
        "\n",
        "![](https://miro.medium.com/max/700/1*ciDgQEjViWLnCbmX-EeSrA.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISPxF50pRDhk"
      },
      "source": [
        "# **Transposed Convolution**\n",
        "\n",
        "Transposed Convolutions are used to upsample the input feature map to a desired output feature map using some learnable parameters.\n",
        "\n",
        "It is also referred to as fractionally strided convolution due since stride over the output is equivalent to fractional stride over the input. For instance, a stride of 2 over the output is 1/2 stride over the input.\n",
        "\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Iyi-V5KRDhk"
      },
      "source": [
        "Applications of Transposed Convolution:\n",
        "\n",
        "* 1)Super- Resolution\n",
        "* 2)Semantic Segmentation\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "RiHoKe47RDhl"
      },
      "source": [
        "# **AutoEncoders**\n",
        "\n",
        "Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wu7Zh8SRDhl"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsQNKPPHRDhm"
      },
      "source": [
        "# Understanding AutoEncoders\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "* Encoder: Encoder is just like a normla ANN model. In which the model learns how to reduce the input dimensions and compress the input data into an encoded representation.\n",
        "* Bottleneck: Bottleneck is nothing but a hidden layer which contains the compressed representation of the input data.\n",
        "* Decoder: In which the model learns how to reconstruct the data from the encoded representation to be as close to the original input as possible.\n",
        "* Reconstruction Loss: This is the method that measures measure how well the decoder is performing and how close the output is to the original input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlaBwXxXRDhn"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3EZwMS8RDhn"
      },
      "source": [
        "# Image Denoising\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "We can use AutoEncoders for denoising as well. Here we are passing noisy data to model as an input and training it to remove the noice from the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg1cBI91RDho"
      },
      "source": [
        "# Data Generation\n",
        "\n",
        "Just like GANs we can use AutoEncoders to generate data. And we can use that data(Noisy) to create robust models.\n",
        "\n",
        "![image.png](attachment:image.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWZD2iIqRDho"
      },
      "source": [
        "# Anomaly Approach\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "* Data description:\n",
        "* Cloud Images - 100\n",
        "* Non Cloud Images- 1499\n",
        "\n",
        "* To find out anomaly(Cloud images) we will train our model only with non-anomaly(Non Cloud images) data. So that our model can understand non anomaly data more, than anomaly data. \n",
        "\n",
        "* When we train our model with non-anomaly data, Reconstruction loss will be less for non-anomaly data compared to anomaly data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRs4E-FeRDho"
      },
      "source": [
        "# **Implementation of Autoencoder for anomaly detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thNWxOfnRDhp"
      },
      "source": [
        "*Loading the required Libraries*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "2x4rQZ2NRDhp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math, re, os, cv2\n",
        "import random\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from kaggle_datasets import KaggleDatasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_addons as tfa\n",
        "from skimage.util import random_noise\n",
        "from skimage.transform import rotate, AffineTransform, warp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iv_ycuhFRDhq"
      },
      "source": [
        "#Path of cloud and Non-cloud datasets\n",
        "path = '../input/cloud-anomaly-detection-images/noncloud/noncloud'\n",
        "path2 = '../input/cloud-anomaly-detection-images/cloud/cloud'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GNhJnmjJRDhq"
      },
      "source": [
        "#Loaded and Preprocessed all the non-cloud satellite images for training\n",
        "all_images=[]\n",
        "import os\n",
        "img_list = os.listdir(path)\n",
        "for i in tqdm(img_list):\n",
        "    img = tf.keras.preprocessing.image.load_img(path+'/'+str(i), target_size=(384,384,3))\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img = img/255.\n",
        "    all_images.append(img)\n",
        "    \n",
        "all_images= np.array(all_images[1:])\n",
        "all_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bri_UODmRDhr"
      },
      "source": [
        "#Show non-cloud images\n",
        "n = 5\n",
        "plt.figure(figsize= (20,10))\n",
        "\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(2, n, i+1)\n",
        "    plt.imshow(all_images[i+50])\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    ax = plt.subplot(2, n, i+1+n)\n",
        "    plt.imshow(all_images[i+20])\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHdVLkQXRDhr"
      },
      "source": [
        "# Augment Non-cloud images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CcpxewP6RDhr"
      },
      "source": [
        "def anticlockwise_rotation(image):\n",
        "    angle= random.randint(0,180)\n",
        "    return rotate(image, angle)\n",
        "\n",
        "def clockwise_rotation(image):\n",
        "    angle= random.randint(0,180)\n",
        "    return rotate(image, -angle)\n",
        "\n",
        "def h_flip(image):\n",
        "    return  np.fliplr(image)\n",
        "\n",
        "def v_flip(image):\n",
        "    return np.flipud(image)\n",
        "\n",
        "def add_noise(image):\n",
        "    return random_noise(image)\n",
        "\n",
        "def blur_image(image):\n",
        "    return cv2.GaussianBlur(img, (9,9),0)\n",
        "\n",
        "#I would not recommend warp_shifting, because it distorts image, but can be used in many use case like \n",
        "#classifying blur and non-blur images\n",
        "def warp_shift(image): \n",
        "    transform = AffineTransform(translation=(0,40))  #chose x,y values according to your convinience\n",
        "    warp_image = warp(image, transform, mode=\"wrap\")\n",
        "    return warp_image\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AoS6sX84RDhr"
      },
      "source": [
        "# aug_images=[]\n",
        "# for i in tqdm(all_images):\n",
        "#     img = add_noise(i)\n",
        "#     img = blur_image(img)\n",
        "#     img = warp_shift(img)\n",
        "#     aug_images.append(img)\n",
        "# aug_images = np.array(aug_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "k3kYf1i7RDhs"
      },
      "source": [
        "# #Show Augmented non-cloud images\n",
        "# n = 5\n",
        "# plt.figure(figsize= (20,10))\n",
        "\n",
        "# for i in range(n):\n",
        "#     ax = plt.subplot(2, n, i+1)\n",
        "#     plt.imshow(aug_images[i+50])\n",
        "#     ax.get_xaxis().set_visible(False)\n",
        "#     ax.get_yaxis().set_visible(False)\n",
        "\n",
        "#     ax = plt.subplot(2, n, i+1+n)\n",
        "#     plt.imshow(aug_images[i+20])\n",
        "#     ax.get_xaxis().set_visible(False)\n",
        "#     ax.get_yaxis().set_visible(False)\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WoUgldqNRDhs"
      },
      "source": [
        "#Config hyperparameters\n",
        "IMAGE_SIZE = [384,384]\n",
        "SEED = 42\n",
        "n_hidden_1 = 512\n",
        "n_hidden_2 = 256\n",
        "n_hidden_3 = 64 \n",
        "n_hidden_4 = 16\n",
        "n_hidden_5 = 8\n",
        "convkernel = (3, 3)  # convolution kernel\n",
        "poolkernel = (2, 2)  # pooling kernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qjpnnAQrRDhs"
      },
      "source": [
        "#seeds\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EybtyFydRDht"
      },
      "source": [
        "# **Cofiguring TPU for Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lPgPm2ixRDht"
      },
      "source": [
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VCPJer_RDht"
      },
      "source": [
        "# Customized autoencoder architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Cvfkc1MGRDht"
      },
      "source": [
        "def get_model():\n",
        "    K.clear_session()\n",
        "    with strategy.scope():\n",
        "        inp1 = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3))\n",
        "\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_1, convkernel, activation='relu', padding='same')(inp1)\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_1, convkernel, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.MaxPooling2D(poolkernel, padding='same')(x)#\n",
        "\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_2, convkernel, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_2, convkernel, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.MaxPooling2D(poolkernel, padding='same')(x)#\n",
        "\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_3, convkernel, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_3, convkernel, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_3, convkernel, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_3, convkernel, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.MaxPooling2D(poolkernel, padding='same')(x)#\n",
        "\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_4, convkernel, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_4, convkernel, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_4, convkernel, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_4, convkernel, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.MaxPooling2D(poolkernel, padding='same')(x)#\n",
        "\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_5, convkernel, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_5, convkernel, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2D(n_hidden_5, convkernel, activation='relu', padding='same')(x)\n",
        "        encoded = tf.keras.layers.Conv2D(n_hidden_5, convkernel, activation='relu', padding='same')(x)\n",
        "\n",
        "\n",
        "        #decoder\n",
        "        x = tf.keras.layers.Conv2DTranspose(n_hidden_5, convkernel, strides=2, activation='relu', padding='same')(encoded)\n",
        "        x = tf.keras.layers.Conv2DTranspose(n_hidden_4, convkernel, strides=2, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2DTranspose(n_hidden_3, convkernel, strides=2, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2DTranspose(n_hidden_2, convkernel, strides=2, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2DTranspose(n_hidden_1, convkernel, strides=1, activation='relu', padding='same')(x)\n",
        "\n",
        "        decoded = tf.keras.layers.Conv2DTranspose(3, convkernel, activation=\"sigmoid\", padding='same')(x)\n",
        "\n",
        "        model = tf.keras.models.Model(inputs = inp1, outputs = decoded)\n",
        "\n",
        "        opt = tfa.optimizers.RectifiedAdam(lr=3e-4)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'mse',\n",
        "            metrics = [tf.keras.metrics.RootMeanSquaredError()]\n",
        "        )\n",
        "\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuLOz2H7RDht"
      },
      "source": [
        "**Used Pretrained VGG19 for Encoder and Transposed convolution for Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZtAg6PVxRDhu"
      },
      "source": [
        "def get_vgg19():\n",
        "    K.clear_session()\n",
        "    with strategy.scope():\n",
        "        image_input = tf.keras.layers.Input(shape = (*IMAGE_SIZE,3))\n",
        "        vg19 = tf.keras.applications.VGG19(input_tensor = image_input, weights = 'imagenet', include_top=False)\n",
        "        encoded = vg19.get_layer('block5_pool').output\n",
        "        #decode\n",
        "        x = tf.keras.layers.Conv2DTranspose(n_hidden_5, convkernel, strides=2, activation='relu', padding='same')(encoded)\n",
        "        x = tf.keras.layers.Conv2DTranspose(n_hidden_4, convkernel, strides=2, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2DTranspose(n_hidden_3, convkernel, strides=2, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2DTranspose(n_hidden_2, convkernel, strides=2, activation='relu', padding='same')(x)\n",
        "        x = tf.keras.layers.Conv2DTranspose(n_hidden_1, convkernel, strides=2, activation='relu', padding='same')(x)\n",
        "        decoded = tf.keras.layers.Conv2DTranspose(3, convkernel, activation=\"sigmoid\", padding='same')(x)\n",
        "        model = tf.keras.models.Model(inputs = image_input, outputs = decoded)\n",
        "        opt = tfa.optimizers.RectifiedAdam(lr=3e-4)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'mse',\n",
        "            metrics = [tf.keras.metrics.RootMeanSquaredError()]\n",
        "        )\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "z9cPMesDRDhu"
      },
      "source": [
        "\n",
        "model=  get_vgg19() #get_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O_KQ0tjZRDhu"
      },
      "source": [
        "#Split the dataset into train and test with a ratio of 80:20.\n",
        "X_train, X_test = train_test_split(all_images, test_size=0.2, random_state=SEED)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1GSjLw_dRDhu"
      },
      "source": [
        "del all_images;  gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NQwd7TsGRDhu"
      },
      "source": [
        "#model training config params\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 16\n",
        "NUM_TRAINING_IMAGES = X_train.shape[0]\n",
        "steps = NUM_TRAINING_IMAGES // BATCH_SIZE\n",
        "NUM_VALID_IMAGES = X_test.shape[0]\n",
        "val_steps = NUM_VALID_IMAGES // BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dOE56x7WRDhv"
      },
      "source": [
        "#Model training\n",
        "sav = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \n",
        "    'Enc'+'.h5', monitor='val_loss', verbose=1, save_best_only=True,\n",
        "    save_weights_only=True, mode='min', save_freq='epoch')\n",
        "# lr scheduler\n",
        "cb_lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.4, patience = 2,\n",
        "                                                      verbose = 1, mode = 'min',min_delta = 0.0001)\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 5, \n",
        "                                                  verbose = 1, min_delta = 0.0001)\n",
        "model.fit(X_train, X_train,\n",
        "      validation_data=(X_test, X_test),\n",
        "      steps_per_epoch=steps,\n",
        "      validation_steps=val_steps,\n",
        "      epochs = EPOCHS,\n",
        "      callbacks= [sav, cb_lr_schedule,early_stopping],\n",
        "      verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "78LjRphIRDhv"
      },
      "source": [
        " [Part 2: Satellite Anomaly Detection[Inference] ](https://www.kaggle.com/ashoksrinivas/satellite-anomaly-detection-inference)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hdLs-NbeRDhv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}