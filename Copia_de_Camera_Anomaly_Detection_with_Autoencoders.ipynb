{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:AzureML]",
      "language": "python",
      "name": "conda-env-AzureML-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Copia de Camera Anomaly Detection with Autoencoders.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsoy/data/blob/main/Copia_de_Camera_Anomaly_Detection_with_Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErW21MnPCnSV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPsuQTrpCnSX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "NUwYMWsQCnSY",
        "outputId": "1c7024b3-df85-400d-ebb6-d658a0426797"
      },
      "source": [
        "# Start building the Auto encoder\n",
        "# Import neccesary libraries\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import Sequential\n",
        "from keras .callbacks import TensorBoard\n",
        "from keras.models import Model\n",
        "from keras import Input,layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Conv2D,UpSampling2D,MaxPooling2D,ZeroPadding2D, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import average_precision_score,mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cc0443a7ea9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mUpSampling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1guhex7PCnSa"
      },
      "source": [
        "#  Data Preprocessing\n",
        "import os,shutil\n",
        "\n",
        "#path to data\n",
        "train_path = r\"c:\\Users\\abulele\\Desktop\\Training_Data\"\n",
        "\n",
        "test_path = r\"c:\\Users\\abulele\\Desktop\\Test_Data\"\n",
        "\n",
        "augment_data =r\"c:\\Users\\abulele\\Desktop\\Training_Data\\data_augmentation\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xwcy2GPCnSa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jslktca2CnSb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmN_bUIlCnSb",
        "outputId": "08f51bcf-610d-4f6d-968e-a8187095984e"
      },
      "source": [
        "\n",
        "# normalize the images and Data Augmentation.\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode=\"input\",\n",
        "    shuffle=True\n",
        "   )\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(150,150),\n",
        "    batch_size=20,\n",
        "    class_mode=\"input\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4658 images belonging to 1 classes.\n",
            "Found 2092 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuLiUHNLCnSd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq2gR4VtCnSd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTBY88YYCnSe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFGcur7GCnSe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbA1A3UTCnSe"
      },
      "source": [
        "# Build an Auto encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B7b_KGcCnSf"
      },
      "source": [
        "## Auto encoders are unsupervised  machine learning models where  the target output (Y) is the input (X), therefore becomes model.fit(X,X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRC9VCjMCnSh"
      },
      "source": [
        "### An auto encoder consists of three layers\n",
        "\n",
        "\n",
        "#### 1. Encoder:\n",
        "##### Encodes the input image or data as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original  image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAMEDlDRCnSh",
        "outputId": "0c644297-99a9-40aa-c493-10c545034898"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(url='https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2018/10/raisr-info-width-2000-528x297.png')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2018/10/raisr-info-width-2000-528x297.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnfBQasmCnSi"
      },
      "source": [
        "#### 2. Code:\n",
        "#####  Feeds the compressed image to the decoder.\n",
        "\n",
        "#### 3. Decoder:\n",
        "##### This layer decodes  the encoded image back to the original dimension.\n",
        "\n",
        "![image.png](attachment:image.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFXc8UonCnSi"
      },
      "source": [
        "\n",
        "\n",
        "<h3 style=\"color:black;\"> How will I use this ? </h1>\n",
        "<br>\n",
        "<ol> \n",
        "    <li> Train it on normal instances, so when we feed the model anomalies they will be easily detected </li>\n",
        "    <br>\n",
        "    <li> To classify new instances we  feed them to input of autoencoder</li>\n",
        "    <br>\n",
        "    <li> Get reconstruction error output and compute the resconstruction error</li>\n",
        "    <br>\n",
        "    <li> Measure the distance between the reconstructed output and input </li>\n",
        "    \n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgV37hLQCnSj"
      },
      "source": [
        "# lets get building. This the Archictecture. A deep autoencoder\n",
        "\n",
        "input_img = Input(shape=(150,150,3)) #  takes image 150X150 pixel with RGB \n",
        "\n",
        "X = Conv2D(16,(3,3), activation='relu',padding=\"same\")(input_img)\n",
        "X = MaxPooling2D((2,2), padding='same')(X)\n",
        "X = Conv2D(8, (3,3), activation='relu',padding=\"same\")(X)\n",
        "X = MaxPooling2D((2,2), padding='same')(X)\n",
        "X = Conv2D(8,(3,3), activation='relu', padding='same')(X)\n",
        "\n",
        "# Compress the image\n",
        "encoded = MaxPooling2D((2,2), padding='same', name='encoder')(X)\n",
        "\n",
        "\n",
        "\n",
        "# decoding. \n",
        "X = Conv2D(8,(3,3), activation='relu',padding=\"same\")(encoded)\n",
        "X = UpSampling2D((2,2))(X)\n",
        "X = Conv2D(8, (3,3), activation='relu',padding=\"same\")(X)\n",
        "X = UpSampling2D((2,2))(X)\n",
        "\n",
        "X = ZeroPadding2D(padding=(1, 1), input_shape=(148, 148, 16))(X)\n",
        "X = Conv2D(16, (3, 3), activation='relu')(X)\n",
        "X = UpSampling2D((2, 2))(X)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# decoding- decodes encoded image back to original \n",
        "decoded = Conv2D(3,(3,3),activation=\"sigmoid\", padding='valid')(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbvUqbu8CnSj"
      },
      "source": [
        "#Lets define an encoder \n",
        "\n",
        "encoder = Model(input_img,encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlK6hJFCCnSk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD634eXMCnSk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL4GMkRXCnSk",
        "outputId": "ec3e5e42-1f80-4dbf-ceb5-256f4a73e8a8"
      },
      "source": [
        "# define autoencoder \n",
        "\n",
        "autoencoder = Model(input_img, decoded) # Defined the model\n",
        "autoencoder.compile(optimizer='adam',loss='mse')\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 150, 150, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 75, 75, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 75, 75, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 38, 38, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 38, 38, 8)         584       \n",
            "_________________________________________________________________\n",
            "encoder (MaxPooling2D)       (None, 19, 19, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 19, 19, 8)         584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 38, 38, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 38, 38, 8)         584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 76, 76, 8)         0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPaddin (None, 78, 78, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 76, 76, 16)        1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 (None, 152, 152, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 150, 150, 3)       435       \n",
            "=================================================================\n",
            "Total params: 4,963\n",
            "Trainable params: 4,963\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNtVDAmBCnSk"
      },
      "source": [
        "# Use Tensorboard to Monitor Model\n",
        "from time import time\n",
        "\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB2oljU0CnSk",
        "outputId": "db9a6cdb-806a-4383-b22e-cb45e5d95fcc"
      },
      "source": [
        "#  Training the autoencoder\n",
        "    \n",
        "#train the model   \n",
        "autoencoder_train = autoencoder.fit_generator(generator=train_generator,steps_per_epoch=20,\n",
        "                        epochs=30,validation_data=test_generator,\n",
        "                         validation_steps=20,shuffle=True,\n",
        "                        callbacks=[tensorboard]\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "20/20 [==============================] - 27s 1s/step - loss: 0.0094 - val_loss: 0.0215\n",
            "Epoch 2/30\n",
            "20/20 [==============================] - 19s 957ms/step - loss: 0.0095 - val_loss: 0.0216\n",
            "Epoch 3/30\n",
            "20/20 [==============================] - 19s 958ms/step - loss: 0.0100 - val_loss: 0.0214\n",
            "Epoch 4/30\n",
            "20/20 [==============================] - 19s 962ms/step - loss: 0.0094 - val_loss: 0.0214\n",
            "Epoch 5/30\n",
            "20/20 [==============================] - 19s 965ms/step - loss: 0.0093 - val_loss: 0.0214\n",
            "Epoch 6/30\n",
            "19/20 [===========================>..] - ETA: 0s - loss: 0.0094"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_k0HuUHCnSl",
        "outputId": "39e6fbb8-b7d7-4313-9fd5-49337d543dfc"
      },
      "source": [
        "loss = autoencoder_train.history['loss']\n",
        "val_loss = autoencoder_train.history['val_loss']\n",
        "epochs = range(100)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlcuwOxXCnSl"
      },
      "source": [
        "#Create the encoder \n",
        "\n",
        "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('encoder').output)\n",
        "\n",
        "encoder.save('encoder.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Goi_kBh2CnSl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LJ78tFBCnSl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYLtwY-xCnSl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE-BWZgVCnSl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Kxf3S-GCnSl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As8S6BoWCnSm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi09WwDkCnSm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5GdCuLcCnSm"
      },
      "source": [
        "for data_batch, labels_batch in test_generator:\n",
        "    print(\"data batch shape: \", data_batch.shape)\n",
        "    print(\"labels batch shape: \", labels_batch.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2If3KmHCnSm"
      },
      "source": [
        "predictions = autoencoder.predict_generator(test_generator, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndNZW74HCnSm"
      },
      "source": [
        "plt.figure(figsize=(17, 10))\n",
        "print(\"Test Images\")\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 10, i+1)\n",
        "    plt.imshow(data_batch[i, ..., 0])\n",
        "    curr_lbl = labels_batch[i]\n",
        "    plt.title(\"input Images\")\n",
        "plt.show()    \n",
        "plt.figure(figsize=(20, 4))\n",
        "print(\"Reconstruction of Test Images\")\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 10, i+1)\n",
        "    plt.title(\"constructed\")\n",
        "    plt.imshow(predictions[i, ..., 0])  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRacZ7IMCnSm"
      },
      "source": [
        "autoencoder.save(\"autoencoders_train.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWFtJQrwCnSn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTqZleg8CnSn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tprfsYObCnSn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpZJCriJCnSn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBS_doFBCnSn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLewTQDvCnSn"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Part two  \n",
        "encoded = Dense(128, activation='relu')(input_img)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)\n",
        "\n",
        "decoded = Dense(32, activation='relu')(encoded)\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(3, activation='sigmoid')(decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP4ctCXSCnSn"
      },
      "source": [
        "autoencoder2 = Model(input_img, decoded)\n",
        "autoencoder2.compile(optimizer='adadelta', loss='mse')\n",
        "\n",
        "autoencoder2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7ZWE6XNCnSn"
      },
      "source": [
        "autoencoder2.fit_generator(generator=train_generator,steps_per_epoch=20,\n",
        "                        epochs=30,validation_data=test_generator,\n",
        "                         validation_steps=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuaApdrzCnSn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}