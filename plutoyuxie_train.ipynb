{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Copia de train.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsoy/data/blob/main/plutoyuxie_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF-DOBKCVsLp"
      },
      "source": [
        "## https://github.com/plutoyuxie/AutoEncoder-SSIM-for-unsupervised-anomaly-detection-"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Det-j5M5VsLr"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EboNmJPWVsLs"
      },
      "source": [
        "from network import AutoEncoder\n",
        "from utils import generate_image_list, augment_images, read_img\n",
        "from options import Options"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtq7Do2rVsLt"
      },
      "source": [
        "cfg = Options().parse()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm-aWHT9VsLu"
      },
      "source": [
        "class data_flow(Sequence):\n",
        "    def __init__(self, filenames, batch_size, grayscale):\n",
        "        self.filenames = filenames\n",
        "        self.batch_size = batch_size\n",
        "        self.grayscale = grayscale\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_x = np.array([read_img(filename, self.grayscale) for filename in batch_x])\n",
        "        \n",
        "        batch_x = batch_x / 255.\n",
        "        return batch_x, batch_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyrva23eVsLv"
      },
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPxkmb8RVsLx"
      },
      "source": [
        "if cfg.aug_dir and cfg.do_aug:\n",
        "    img_list = generate_image_list(cfg)\n",
        "    augment_images(img_list, cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD2Nz5FsVsLy"
      },
      "source": [
        "dataset_dir = cfg.aug_dir if cfg.aug_dir else cfg.train_data_dir\n",
        "file_list = glob(dataset_dir + '/*')\n",
        "num_valid_data = int(np.ceil(len(file_list) * 0.2))\n",
        "data_train = data_flow(file_list[:-num_valid_data], cfg.batch_size, cfg.grayscale)\n",
        "data_valid = data_flow(file_list[-num_valid_data:], cfg.batch_size, cfg.grayscale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6OM5fE3VsLz"
      },
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhZC7MPGVsL0"
      },
      "source": [
        "if cfg.loss == 'ssim_loss':\n",
        "    \n",
        "    @tf.function\n",
        "    def ssim_loss(gt, y_pred, max_val=1.0):\n",
        "        return 1 - tf.reduce_mean(tf.image.ssim(gt, y_pred, max_val=max_val))\n",
        "    \n",
        "    loss = ssim_loss\n",
        "elif cfg.loss == 'ssim_l1_loss':\n",
        "    \n",
        "    @tf.function\n",
        "    def ssim_l1_loss(gt, y_pred, max_val=1.0):\n",
        "        ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(gt, y_pred, max_val=max_val))\n",
        "        L1 = tf.reduce_mean(tf.abs(gt - y_pred))\n",
        "        return ssim_loss + L1 * cfg.weight\n",
        "    \n",
        "    loss = ssim_l1_loss\n",
        "else:\n",
        "    loss = 'mse'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KC-HcO9VsL1"
      },
      "source": [
        "network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipu2C3aFVsL1"
      },
      "source": [
        "autoencoder = AutoEncoder(cfg)\n",
        "optimizer = Adam(lr=cfg.lr, decay=cfg.decay)\n",
        "autoencoder.compile(optimizer=optimizer, loss=loss, metrics=['mae'] if loss == 'mse' else ['mse'])\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfTyPu4IVsL1"
      },
      "source": [
        "earlystopping = EarlyStopping(patience=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSceSMv9VsL2"
      },
      "source": [
        "checkpoint = ModelCheckpoint(os.path.join(cfg.chechpoint_dir, '{epoch:02d}-{val_loss:.5f}.hdf5'), save_best_only=True,\n",
        "                            period=1, mode='auto', verbose=1, save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppvJnln5VsL2"
      },
      "source": [
        "autoencoder.fit(data_train, epochs=cfg.epochs, validation_data=data_valid, callbacks=[checkpoint, earlystopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_g1ZHxUVsL3"
      },
      "source": [
        "show reconstructed images"
      ]
    }
  ]
}